{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ1rkwI9SpWmxiPf4jX8U4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivang-Quantum/QuantaPytha/blob/Tutort/Deep%20Learning/DataPreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inmdqGFAKcZl"
      },
      "outputs": [],
      "source": [
        "#Tokenization\n",
        "# Sequencing\n",
        "# Padding\n",
        "# Stemming\n",
        "# Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fmh3MUZMKrnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "TPs8P4RAKklE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=['We Like Machine Learning']\n",
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "BKTkO-aTLHkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentence)"
      ],
      "metadata": {
        "id": "LC_avihpLT6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_AkWDj_Lc2f",
        "outputId": "60d27768-a368-4102-950a-a6b6363a550c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'we': 1, 'like': 2, 'machine': 3, 'learning': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat Words\n",
        "sentence=['We like Machine Learning and Deep Learning']"
      ],
      "metadata": {
        "id": "aLuLpfxcLhhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentence)"
      ],
      "metadata": {
        "id": "BkZqdpDIMDs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r9iXeL9MNSX",
        "outputId": "21e0023e-bcba-479b-9597-90519cbf8fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning': 1, 'we': 2, 'like': 3, 'machine': 4, 'and': 5, 'deep': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The ones that have higher frequency comes first"
      ],
      "metadata": {
        "id": "IygMUxJWMRi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization is not case senitivie\n",
        "# Tokenization removes special Characters"
      ],
      "metadata": {
        "id": "OZPbS-5FMgVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Special Characteristics not considered\n",
        "sentence=['We like Machine Learning and Deep Learning ...........!!!']"
      ],
      "metadata": {
        "id": "GzjMeWDzMrRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentence)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-oIk1MMM0I3",
        "outputId": "2ac7a808-5a87-45ef-c446-ab181377d93f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning': 1, 'we': 2, 'like': 3, 'machine': 4, 'and': 5, 'deep': 6}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=['we are learning natural language process',\n",
        "          'we have learned how artificial neural network works']"
      ],
      "metadata": {
        "id": "KSOW0yvgNA_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentence)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ns53u9IN_iS",
        "outputId": "c7ef85b8-9057-4567-faef-d4e38dec4988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning': 1,\n",
              " 'we': 2,\n",
              " 'like': 3,\n",
              " 'machine': 4,\n",
              " 'and': 5,\n",
              " 'deep': 6,\n",
              " 'are': 7,\n",
              " 'natural': 8,\n",
              " 'language': 9,\n",
              " 'process': 10,\n",
              " 'have': 11,\n",
              " 'learned': 12,\n",
              " 'how': 13,\n",
              " 'artificial': 14,\n",
              " 'neural': 15,\n",
              " 'network': 16,\n",
              " 'works': 17}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SEQUENCING  - Piece of text as the sequence of numbers"
      ],
      "metadata": {
        "id": "2ovNf7hwOBZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['We are learning text preprocessing',\n",
        "            'Tokenization refers to representing each word as a Token',\n",
        "            'Sequencing referes to representing text as sequence of tokens']"
      ],
      "metadata": {
        "id": "VH7q2VjQMnL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(sentence)\n",
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj_qwZlXPNkB",
        "outputId": "68df2ca2-71c0-477a-f0c6-30efeb2fedca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning': 1,\n",
              " 'we': 2,\n",
              " 'like': 3,\n",
              " 'machine': 4,\n",
              " 'and': 5,\n",
              " 'deep': 6,\n",
              " 'are': 7,\n",
              " 'text': 8,\n",
              " 'to': 9,\n",
              " 'representing': 10,\n",
              " 'as': 11,\n",
              " 'natural': 12,\n",
              " 'language': 13,\n",
              " 'process': 14,\n",
              " 'have': 15,\n",
              " 'learned': 16,\n",
              " 'how': 17,\n",
              " 'artificial': 18,\n",
              " 'neural': 19,\n",
              " 'network': 20,\n",
              " 'works': 21,\n",
              " 'preprocessing': 22,\n",
              " 'tokenization': 23,\n",
              " 'refers': 24,\n",
              " 'each': 25,\n",
              " 'word': 26,\n",
              " 'a': 27,\n",
              " 'token': 28,\n",
              " 'sequencing': 29,\n",
              " 'referes': 30,\n",
              " 'sequence': 31,\n",
              " 'of': 32,\n",
              " 'tokens': 33}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences=tokenizer.texts_to_sequences(sentence)"
      ],
      "metadata": {
        "id": "U8iUec-oPcWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd1SAbpaPqd1",
        "outputId": "d56e2f8f-230b-411d-f555-80519b5e2ddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 7, 1, 8, 22],\n",
              " [23, 24, 9, 10, 25, 26, 11, 27, 28],\n",
              " [29, 30, 9, 10, 8, 11, 31, 32, 33]]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directly we can generate sequence once when the tokenizer has a vocubilary of the words it is trained on, any new word gets ignored, e.g. 'padding'\n",
        "tokenizer.texts_to_sequences(['Text Preprocessing tokenization, sequencing, padding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrUJpRVDPs8S",
        "outputId": "99c08095-10a6-48e6-9a78-40599876c60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 22, 23, 29]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Out of Vocubulary is to address when new word is used\n",
        "\n",
        "sentence = ['We are learning text preprocessing',\n",
        "            'Tokenization refers to representing each word as a Token',\n",
        "            'Sequencing referes to representing text as sequence of tokens']\n",
        "tokenizer = Tokenizer(oov_token='#OOV')\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "tokenizer.word_index\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_RVr7-cSenN",
        "outputId": "8aca1b34-0d01-48df-c343-6ba0d6d0ca6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#OOV': 1,\n",
              " 'text': 2,\n",
              " 'to': 3,\n",
              " 'representing': 4,\n",
              " 'as': 5,\n",
              " 'we': 6,\n",
              " 'are': 7,\n",
              " 'learning': 8,\n",
              " 'preprocessing': 9,\n",
              " 'tokenization': 10,\n",
              " 'refers': 11,\n",
              " 'each': 12,\n",
              " 'word': 13,\n",
              " 'a': 14,\n",
              " 'token': 15,\n",
              " 'sequencing': 16,\n",
              " 'referes': 17,\n",
              " 'sequence': 18,\n",
              " 'of': 19,\n",
              " 'tokens': 20}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(['Text Preprocessing tokenization, sequencing, padding'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3PttSiaUeZL",
        "outputId": "c16ca746-fae5-46ce-df02-f19a8e2fccf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[2, 9, 10, 16, 1]]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PADDING - Adding 0s to character so as to make them all of equal length"
      ],
      "metadata": {
        "id": "PO5Ur2y8UiOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['We like machine learning',\n",
        "            'we are learning tokanization',\n",
        "            'we are learning sequencing',\n",
        "            'we are learning padding techniques',\n",
        "            'machine Learning is fun']\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='#OOV')\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce_Hdi6CU_Z0",
        "outputId": "cff1a014-7445-4291-f785-aacf552ed098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[3, 6, 5, 2], [3, 4, 2, 7], [3, 4, 2, 8], [3, 4, 2, 9, 10], [5, 2, 11, 12]]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "padded_seq = pad_sequences(sequences)"
      ],
      "metadata": {
        "id": "0qf-wadkVxbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cUQM9pzWp3D",
        "outputId": "12bf059a-df13-479e-a31d-c5c9cff698ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  3,  6,  5,  2],\n",
              "       [ 0,  3,  4,  2,  7],\n",
              "       [ 0,  3,  4,  2,  8],\n",
              "       [ 3,  4,  2,  9, 10],\n",
              "       [ 0,  5,  2, 11, 12]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# padding parameter to place 0 pre/post\n",
        "padded_seq = pad_sequences(sequences,padding='post')\n",
        "padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH6H52PiWs9e",
        "outputId": "11a7f45b-9f84-49fc-a446-921a79e78e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  6,  5,  2,  0],\n",
              "       [ 3,  4,  2,  7,  0],\n",
              "       [ 3,  4,  2,  8,  0],\n",
              "       [ 3,  4,  2,  9, 10],\n",
              "       [ 5,  2, 11, 12,  0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = ['We like machine learning',\n",
        "            'we are learning tokanization',\n",
        "            'we are learning sequencing',\n",
        "            'we are learning padding techniques',\n",
        "            'machine Learning is fun',\n",
        "            'The padding happens consider length of the maximum sentence, let us check this']\n",
        "\n",
        "tokenizer = Tokenizer(oov_token='#OOV')\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "sequences\n",
        "\n",
        "padded_seq = pad_sequences(sequences)\n",
        "padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB5YpWuIXKdB",
        "outputId": "2a9aaf02-2002-48bd-c4dc-5adc8af2c978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  8,  5,  2],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  4,  2,  9],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  3,  4,  2, 10],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  3,  4,  2,  6, 11],\n",
              "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  5,  2, 12, 13],\n",
              "       [ 7,  6, 14, 15, 16, 17,  7, 18, 19, 20, 21, 22, 23]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will need to ensure that the outlyer does not cause more '0' in your data, thus there has to be optimization here\n",
        "padded_seq = pad_sequences(sequences,padding='post',maxlen=8)\n",
        "padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgct8kbDXmAE",
        "outputId": "875630d3-29da-4e7d-8632-78170474dd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  8,  5,  2,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2,  9,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2, 10,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2,  6, 11,  0,  0,  0],\n",
              "       [ 5,  2, 12, 13,  0,  0,  0,  0],\n",
              "       [17,  7, 18, 19, 20, 21, 22, 23]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note here the last (larger one get truncated), it is by default 'pre', let us try post\n",
        "padded_seq = pad_sequences(sequences,padding = 'post', maxlen = 8, truncating = 'post')\n",
        "padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEIupRtzYSgG",
        "outputId": "daf1d253-ecee-4a5f-f248-9b4ab0bd6360"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3,  8,  5,  2,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2,  9,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2, 10,  0,  0,  0,  0],\n",
              "       [ 3,  4,  2,  6, 11,  0,  0,  0],\n",
              "       [ 5,  2, 12, 13,  0,  0,  0,  0],\n",
              "       [ 7,  6, 14, 15, 16, 17,  7, 18]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer=PorterStemmer()\n",
        "stemmer.stem('breaking')"
      ],
      "metadata": {
        "id": "372vvwhJZALj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "5e39fe30-eeac-4272-e511-388b4f1bfab9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'break'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Stemming not working accurately for word like 'changes'\n",
        "print (stemmer.stem('breaks'))\n",
        "print (stemmer.stem('breaking'))\n",
        "print (stemmer.stem('broke'))\n",
        "print (stemmer.stem('broken'))\n",
        "print (stemmer.stem('changes'))\n",
        "print (stemmer.stem('changed'))\n",
        "print (stemmer.stem('changing'))\n",
        "print (stemmer.stem('writes'))\n",
        "print (stemmer.stem('writing'))\n",
        "print (stemmer.stem('wrote'))\n",
        "print (stemmer.stem('write'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzM2R5VGpGlN",
        "outputId": "4a99b14d-ac99-4451-f502-54429540c36b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "break\n",
            "break\n",
            "broke\n",
            "broken\n",
            "chang\n",
            "chang\n",
            "chang\n",
            "write\n",
            "write\n",
            "wrote\n",
            "write\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lamatization\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egVOBLwnpy-k",
        "outputId": "fc52fcd2-ceb1-4849-c8d4-9bf3bc3ef347"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "lemmatizer.lemmatize('breaks',pos='v')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "KL9QOZl3qkaG",
        "outputId": "126a23df-cdde-4a2a-f748-2f415bdc87a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'break'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (lemmatizer.lemmatize('breaks',pos='v'))\n",
        "print (lemmatizer.lemmatize('breaking',pos='v'))\n",
        "print (lemmatizer.lemmatize('broke',pos='v'))\n",
        "print (lemmatizer.lemmatize('broken',pos='v'))\n",
        "print (lemmatizer.lemmatize('changes',pos='v'))\n",
        "print (lemmatizer.lemmatize('changed',pos='v'))\n",
        "print (lemmatizer.lemmatize('changing',pos='v'))\n",
        "print (lemmatizer.lemmatize('writes',pos='v'))\n",
        "print (lemmatizer.lemmatize('writing',pos='v'))\n",
        "print (lemmatizer.lemmatize('wrote',pos='v'))\n",
        "print (lemmatizer.lemmatize('write',pos='v'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3dh5b6hri1y",
        "outputId": "211003dc-bad6-47bb-f933-c6139f2ce65a"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "break\n",
            "break\n",
            "break\n",
            "break\n",
            "change\n",
            "change\n",
            "change\n",
            "write\n",
            "write\n",
            "write\n",
            "write\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTGLRhMpsj-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoEs4ORgsW-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f7mfxNSrsB5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XCBt_7JKW7jm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2M3mTx55Wab6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S8DduLDCWRa6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}